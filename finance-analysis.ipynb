{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 # SELECT sql FROM sqlite_master WHERE name='foo';\n",
    "import csv\n",
    "import hashlib\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import unidecode\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "# pd.set_option('display.max_rows', 300)\n",
    "# pd.set_option('auto_truncate_string_exceeding_this_length', 1000)\n",
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "def toNumber(x):\n",
    "    try:\n",
    "        return float(x.replace('\\'', '').replace(',', '.'))\n",
    "    except Exception as e:\n",
    "        pass # print(e)\n",
    "    return float(x)\n",
    "\n",
    "def hashDateDescription(x):\n",
    "    return x[0].strftime(\"%Y-%m-%d-\") + hashlib.md5((x[1]+str(x[2])).encode('utf-8')).hexdigest()[:8]\n",
    "\n",
    "def hashBankDescription(x):\n",
    "    val = ''.join([str(x) for x in x])\n",
    "    return hashlib.md5(val.encode('utf-8')).hexdigest()[:16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "# https://github.com/uehara1414/df2gspread\n",
    "from df2gspread import df2gspread as d2g\n",
    "from df2gspread import gspread2df as g2d\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('finance-sheets-089599011f90.json', scope)\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Rule(ABC):\n",
    "    @abstractmethod\n",
    "    def Match(description):\n",
    "        pass\n",
    "\n",
    "class ExactRule(Rule):\n",
    "    pass\n",
    "\n",
    "class RegexRule(Rule):\n",
    "    pass\n",
    "\n",
    "class Category():\n",
    "    def __init__(self, name, index, parent_category=None):\n",
    "        self.name = name\n",
    "        self.index = index\n",
    "        self.parent_category = parent_category\n",
    "        self.rules = []\n",
    "        self.subcategories = []\n",
    "    \n",
    "    def __getitem__(self, sliced):\n",
    "        return self.subcategories[sliced]\n",
    "    \n",
    "    def __str__(self, subcategories=True, rules=True, numbered=False, prefix=''):\n",
    "        ret = []\n",
    "        \n",
    "        name = prefix\n",
    "        if numbered: name += str(self.index) + '. '\n",
    "        name += self.name\n",
    "        ret.append(name)\n",
    "        \n",
    "        if subcategories:\n",
    "            ret.extend([category.__str__(\n",
    "            subcategories=subcategories,\n",
    "            rules=rules,\n",
    "            numbered=numbered,\n",
    "            prefix='\\t'\n",
    "        ) for category in self.subcategories])\n",
    "        \n",
    "        return '\\n'.join(ret)\n",
    "    \n",
    "    def AddSubCategory(self, name, index):\n",
    "        subcategory = Category(name, index, self)\n",
    "        self.subcategories.append(subcategory)\n",
    "        return subcategory\n",
    "        \n",
    "    def AddRule(self, rule):\n",
    "        self.rules.append(rule)\n",
    "    \n",
    "    def ListRules(self, prefix=''):\n",
    "        return '\\n'.join([prefix+str(rule) for rule in self.rules])\n",
    "    \n",
    "    def _formatRule(self, rule, prefix=''):\n",
    "        return str(prefix) + str(rule)\n",
    "\n",
    "    def _formatCategory(self, index, numbered, prefix=''):\n",
    "        index = '' if not numbered else str(index) + '. '\n",
    "        return str(prefix) + str(index) + self.name\n",
    "\n",
    "class Categories():\n",
    "    def __init__(self, filename):\n",
    "        categories = []\n",
    "        with open(filename) as f:\n",
    "            num_categories = 0\n",
    "            for line in f:\n",
    "                line = line.rstrip()\n",
    "                if not line: continue\n",
    "                name = line.strip()\n",
    "                \n",
    "                if line[0] == '\\t':\n",
    "                    categories[-1].AddSubCategory(name, num_subcategories)\n",
    "                    num_subcategories += 1\n",
    "                else:\n",
    "                    category = Category(name, num_categories)\n",
    "                    num_categories += 1\n",
    "                    num_subcategories = 0\n",
    "                    categories.append(category) \n",
    "        self.categories = categories\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.list(True)\n",
    "    \n",
    "    def __getitem__(self, sliced):\n",
    "        return self.categories[sliced]\n",
    "    \n",
    "    def Iterate(self, main=True, sub=True):\n",
    "        for c in self.categories:\n",
    "            if main: yield c\n",
    "            \n",
    "            if not sub: continue\n",
    "            for cc in c.subcategories:\n",
    "                yield cc\n",
    "                \n",
    "    def Save(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write('\\n'.join([x.__str__() for x in self]))\n",
    "\n",
    "categories = Categories('categories.txt')\n",
    "# categories.Save('test.txt')\n",
    "# print('\\n'.join([x.__str__(subcategories=True, rules=True, numbered=True) for x in categories]))\n",
    "# print('\\n'.join([x.__str__(subcategories=False, rules=True, numbered=True) for x in categories.Iterate(False)]))\n",
    "\n",
    "a = []\n",
    "for c in categories:\n",
    "    a.append((None, c.name))\n",
    "    \n",
    "    for sc in c:\n",
    "        a.append((sc.parent_category.index, sc.name))\n",
    "\n",
    "conn = sqlite3.connect(\"transactions.db\")\n",
    "apd = pd.DataFrame(a)\n",
    "apd.columns = ['ParentCategoryId', 'Name']\n",
    "apd.to_sql(\"Categories\", conn, if_exists=\"replace\", index_label='CategoryId')\n",
    "\n",
    "apd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Bank(Enum):\n",
    "    FIO = 1\n",
    "    UBS_transaction = 2\n",
    "    UBS_export = 3\n",
    "    CHASE = 4\n",
    "\n",
    "def DetectEncoding(filename, read_lines=20):\n",
    "    encodings = ['utf-8-sig', 'utf-8', 'windows-1250']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(filename, encoding=encoding) as f:\n",
    "                return encoding, [next(f) for x in range(read_lines)]\n",
    "        except StopIteration as e:\n",
    "            with open(filename, encoding=encoding) as f:\n",
    "                return encoding, f.readlines()\n",
    "        except UnicodeDecodeError as e:\n",
    "            pass\n",
    "    raise Error('Unknown Encoding for file {}'.format(filename))\n",
    "    \n",
    "def GuessBank(filename):\n",
    "    encoding, lines = DetectEncoding(filename)\n",
    "\n",
    "    if lines[0] == 'sep=;\\n' and lines[1] == 'Account number;Card number;Account/Cardholder;Purchase date;Booking text;Sector;Amount;Original currency;Rate;Currency;Debit;Credit;Booked\\n':\n",
    "        return encoding, Bank.UBS_transaction\n",
    "    if lines[0] == 'Valuation date;Banking relationship;Portfolio;Product;IBAN;Ccy.;Date from;Date to;Description;Trade date;Booking date;Value date;Description 1;Description 2;Description 3;Transaction no.;Exchange rate in the original amount in settlement currency;Individual amount;Debit;Credit;Balance\\n':\n",
    "        return encoding, Bank.UBS_export\n",
    "    if lines[0] == 'Details,Posting Date,Description,Amount,Type,Balance,Check or Slip #\\n':\n",
    "        return encoding, Bank.CHASE\n",
    "    if lines[14] == 'ID pohybu;Datum;Objem;Měna;Protiúčet;Název protiúčtu;Kód banky;Název banky;KS;VS;SS;Uživatelská identifikace;Zpráva pro příjemce;Typ;Provedl;Upřesnění;Komentář;BIC;ID pokynu\\n':\n",
    "        return encoding, Bank.FIO\n",
    "    \n",
    "    print(lines[:2])\n",
    "    raise Warning('Could not detect Bank for file {}'.format(filename))\n",
    "\n",
    "def ParseFIO(filename, encoding):\n",
    "    # Parse Metadata\n",
    "    with open(filename, encoding=encoding) as f:\n",
    "        metadata = dict(next(f).strip().split(';') for x in range(13))\n",
    "    \n",
    "    # ID pohybu, Datum, Objem, Měna, Protiúčet, Název protiúčtu, Kód banky, \n",
    "    # Název banky, KS, VS, SS, Uživatelská identifikace, Zpráva pro příjemce,\n",
    "    # Typ, Provedl, Upřesnění, Komentář, BIC, ID pokynu\n",
    "    df = pd.read_csv(filename, skiprows=14, sep=';', index_col=False, dtype=str, encoding=encoding)\n",
    "\n",
    "    df['Uživatelská identifikace'] = df['Uživatelská identifikace'].fillna('')\n",
    "    df['Zpráva pro příjemce'] = df['Zpráva pro příjemce'].fillna('')\n",
    "    df['Komentář'] = df['Komentář'].fillna('')\n",
    "    df['Amount'] = df['Objem'].apply(toNumber).fillna(0)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'TransactionId': df['ID pohybu'],\n",
    "        'PurchaseDate': df['Datum'].apply(pd.to_datetime, format=\"%d.%m.%Y\", errors='coerce'),\n",
    "        'Amount': df['Amount'],\n",
    "        'Currency': df['Měna'],\n",
    "        'Description': df[['Zpráva pro příjemce', 'Uživatelská identifikace', 'Komentář']].apply(lambda x: ' '.join(pd.unique(x)), axis=1),\n",
    "        'Balance': df['Amount'].cumsum() + toNumber(metadata['openingBalance']),\n",
    "        'TransactionType': df['Typ'].fillna('')\n",
    "    }).iloc[::-1].sort_values(by='PurchaseDate', ascending=False, kind='mergesort')\n",
    "\n",
    "def ParseCHASE(filename, encoding):\n",
    "    # Details, Posting Date, Description, Amount, Type, Balance, Check or Slip\n",
    "    df = pd.read_csv(filename, skiprows=0, sep=',', index_col=False, dtype=str, encoding=encoding)\n",
    "\n",
    "    df['Description'] = df['Description'].fillna('')\n",
    "    df['PurchaseDate'] = df['Posting Date'].apply(pd.to_datetime, format=\"%m/%d/%Y\", errors='coerce')\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'TransactionId': df[['PurchaseDate', 'Description', 'Amount']].apply(hashDateDescription, axis=1),\n",
    "        'PurchaseDate': df['PurchaseDate'],\n",
    "        'Amount': df['Amount'].apply(toNumber).fillna(0),\n",
    "        'Currency': 'USD',\n",
    "        'Description': df['Description'],\n",
    "        'Balance': df['Balance'].apply(toNumber).fillna(0),\n",
    "    })\n",
    "\n",
    "def ParseUBS_transactions(filename, encoding):\n",
    "    # Account number, Card number, Account/Cardholder, Purchase date,Booking text,\n",
    "    # Sector, Amount, Original currency, Rate, Currency, Debit, Credit, Booked\n",
    "    df = pd.read_csv(filename, skiprows=1, sep=';', index_col=False, dtype=str, encoding=encoding)\n",
    "\n",
    "    df['AmountCalculated'] = df['Credit'].apply(toNumber).fillna(0) - df['Debit'].apply(toNumber).fillna(0)\n",
    "    df['PurchaseDate'] = df['Purchase date'].apply(pd.to_datetime, format=\"%d.%m.%Y\")\n",
    "    df['Description'] = df['Booking text'].fillna('')\n",
    "\n",
    "    # Remove rows defined by descriptionsToRemove\n",
    "    descriptionsToRemove = ['Balance brought forward', 'DIRECT DEBIT', 'Total per currency', 'Total card bookings']\n",
    "    matchingDescriptions = df['Description'].str.contains('|'.join(descriptionsToRemove))\n",
    "    noCardNumber = df['Card number'].isnull()\n",
    "    df.drop(df[matchingDescriptions & noCardNumber].index, inplace=True)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'TransactionId': df[['PurchaseDate', 'Description', 'AmountCalculated']].apply(hashDateDescription, axis=1),\n",
    "        'PurchaseDate': df['PurchaseDate'],\n",
    "        'Amount': df['AmountCalculated'],\n",
    "        'Currency': df['Currency'],\n",
    "        'Description': df['Description'],\n",
    "        # Extra\n",
    "        'ExcRateToCHF': df['Rate'].apply(toNumber).fillna(0),\n",
    "        'OriginalAmount': df['Amount'].apply(toNumber),\n",
    "        'OriginalCurrency': df['Original currency'],\n",
    "        'UbsCategory': df['Sector'],\n",
    "    }).iloc[::-1].sort_values(by='PurchaseDate', ascending=False, kind='mergesort')\n",
    "\n",
    "def ParseUBS_export(filename, encoding):\n",
    "    # Valuation date, Banking relationship, Portfolio, Product, IBAN, Ccy.,\n",
    "    # Date from, Date to, Description, Trade date, Booking date, Value date,\n",
    "    # Description 1, Description 2, Description 3, Transaction no.,\n",
    "    # Exchange rate in the original amount in settlement currency,\n",
    "    # Individual amount, Debit, Credit, Balance\n",
    "    df = pd.read_csv(filename, skiprows=0, sep=';', index_col=False, dtype=str, encoding=encoding)\n",
    "    df = df.iloc[:-3] # remove last three rows: 'Summary'\n",
    "\n",
    "    df['Debit'] = df['Debit'].apply(toNumber).fillna(0)\n",
    "    df['Credit'] = df['Credit'].apply(toNumber).fillna(0)\n",
    "    df['Individual amount'] = df['Individual amount'].apply(toNumber).fillna(0)\n",
    "    df['Description 2'] = df['Description 2'].fillna('')\n",
    "    df['Description 3'] = df['Description 3'].fillna('')\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'TransactionId': df['Transaction no.'],\n",
    "        'PurchaseDate': df['Trade date'].apply(pd.to_datetime, format=\"%d.%m.%Y\"),\n",
    "        'Amount': df['Credit'] - df['Debit'] + df['Individual amount'],\n",
    "        'Currency': df['Ccy.'],\n",
    "        'Description': df[['Description 2', 'Description 3']].apply(lambda x: '\\n'.join(x), axis=1),\n",
    "        'Balance': df['Balance'].apply(toNumber).fillna(0),\n",
    "        # Extra\n",
    "        'ExcRateToCHF': df['Exchange rate in the original amount in settlement currency'],\n",
    "        'TransactionType': df['Description 1'],\n",
    "    })\n",
    "\n",
    "    # Differentiate Multi PayNet Orders\n",
    "    tid = df[df.TransactionType=='Multi PayNet Order']\n",
    "    df.drop(tid.index, inplace=True) # Drop Sum rows\n",
    "    filtered = df[df.TransactionId.isin(tid.TransactionId)]\n",
    "    df.loc[filtered.index, 'Description'] = filtered.TransactionType + '\\n' + filtered.Description\n",
    "    df.loc[filtered.index, 'TransactionType'] = 'Multi PayNet Order'\n",
    "    # Create new IDs by appending numbers\n",
    "    decreasingSeries = pd.Series(range(len(filtered.index)-1,-1,-1)).astype(str)\n",
    "    newTransactionIds = filtered.TransactionId.str.cat(decreasingSeries)\n",
    "    df.loc[filtered.index, 'TransactionId'] = newTransactionIds\n",
    "\n",
    "    # Group by UBS bank charges\n",
    "    mapping = {col:'first' for col in df.columns.values}\n",
    "    mapping['Amount'] = 'sum'\n",
    "    df = df.groupby('TransactionId', sort=False).agg(mapping).reset_index(drop=True)\n",
    "    df.loc[df['TransactionType']=='Balance of service prices', 'Description'] = 'UBS charges'\n",
    "    \n",
    "    # Remove Direct Debit since we have Credit Card transactions\n",
    "    df.drop(df[df['TransactionType'] == 'Direct Debit'].index, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def GroupByTransactionIdRemoveEmpty(df):\n",
    "    # Group by TransactionId: joins together credit card fees\n",
    "    mapping = {col:'first' for col in df.columns.values}\n",
    "    mapping['Amount'] = 'sum'\n",
    "    df = df.groupby('TransactionId', sort=False).agg(mapping)\n",
    "\n",
    "    # Remove transactions with 0 amount\n",
    "    df.drop(df[df.Amount==0].index, inplace=True)\n",
    "    return df\n",
    "\n",
    "def CommonPostprocessing(df, path, bank):\n",
    "    dirs, file = os.path.split(path)\n",
    "    dirs, last_folder = os.path.split(dirs)\n",
    "\n",
    "    df = GroupByTransactionIdRemoveEmpty(df)\n",
    "\n",
    "    # Add metadata\n",
    "    df['AccountFolder'] = last_folder\n",
    "    df['Filename'] = file\n",
    "    df['BankEnum'] = bank\n",
    "    \n",
    "    df['OriginalDescription'] = df['Description']\n",
    "    df['Description'] = df['Description'].apply(CleanText)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def CommonPostprocessingAfterJoin(df):\n",
    "#     df = GroupByTransactionIdRemoveEmpty(df)\n",
    "    df.drop_duplicates(subset=['PurchaseDate','TransactionId'], inplace=True)\n",
    "    df.sort_values(by='PurchaseDate', ascending=False, kind='mergesort', inplace=True)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def LoadTransactions(filename):\n",
    "    encoding, bank = GuessBank(filename)\n",
    "    \n",
    "    bankToParse = {\n",
    "        Bank.FIO: ParseFIO,\n",
    "        Bank.UBS_transaction: ParseUBS_transactions,\n",
    "        Bank.UBS_export: ParseUBS_export,\n",
    "        Bank.CHASE: ParseCHASE,\n",
    "    }\n",
    "    \n",
    "    transactions = bankToParse[bank](filename, encoding)\n",
    "    \n",
    "    return CommonPostprocessing(transactions, filename, str(bank)[5:])\n",
    "\n",
    "def LoadAllTransactions(folder, regex = '*'):\n",
    "    excluded = [\n",
    "        \"Revolut\",\n",
    "        \"U2400299.2018.dividends\",\n",
    "    ]\n",
    "    dfs = []\n",
    "    csv_files = glob.glob(os.path.join(folder + \"/**/\" + regex + \".csv\"), recursive=True)\n",
    "    for filename in csv_files:\n",
    "#         print(filename)\n",
    "        if (any(x in filename for x in excluded)):\n",
    "            continue\n",
    "        try:\n",
    "            dfs.append(LoadTransactions(filename))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(filename)\n",
    "            raise e\n",
    "    return CommonPostprocessingAfterJoin(pd.concat(dfs, copy=False, ignore_index=True))\n",
    "\n",
    "def CleanText(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ', text) # nonprintable characters  \n",
    "    text = re.sub(r'[^\\w ]',r' ', text)\n",
    "    text = re.sub(r'\\d',r' ', text)\n",
    "    text = re.sub(r'(^| )\\w( |$)', '', text)\n",
    "    text = re.sub('[ \\t\\n]+', ' ', text)\n",
    "#     text = re.sub('\\d\\S*', '', text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'transactions/2017_12_invoice_17_03_2018 18_52_50.csv'\n",
    "# df = pd.read_csv(filename, skiprows=1, sep=';', index_col=False, dtype=str, encoding='windows-1250')\n",
    "df = LoadTransactions(filename)\n",
    "df\n",
    "# df.groupby(['AccountFolder', df.PurchaseDate.dt.to_period(\"M\")]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'transactions/Chase3885_Activity_20180403.CSV'\n",
    "# df = pd.read_csv(filename, skiprows=0, sep=',', encoding='UTF-8', index_col=False)\n",
    "df = LoadTransactions(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'C:/Users/svecon/Google Drive/Finance\\Statements\\Fio pracovni\\2018_06_statement.csv'\n",
    "df = pd.read_csv(filename, skiprows=13, sep=';', index_col=False, dtype=str)\n",
    "# df = LoadTransactions(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'C:/Users/svecon/Google Drive/Finance/Statements/Fio pracovni/2017_09_statement.csv'\n",
    "# df = pd.read_csv(filename, skiprows=0, sep=';', encoding='UTF-8', index_col=False).dropna(thresh=10)\n",
    "# df.groupby(['Transaction no.']).agg({'Description 1': 'first', 'Individual amount': np.sum})\n",
    "# df[df['Exchange rate in the original amount in settlement currency'].notnull()]\n",
    "# df\n",
    "df = ParseFIO(filename, \"utf-8\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:\\\\Users\\\\svecon\\\\Google Drive\\\\Finance\\\\Statements'\n",
    "def CalculateBalances(folder, output_file='Balances.csv'):\n",
    "    df = LoadAllTransactions(folder)\n",
    "    \n",
    "    # Group by Months and Account\n",
    "    df = df.groupby([df.PurchaseDate.dt.to_period(\"M\"), 'AccountFolder'], sort=False)\n",
    "    df = df.agg({'Balance': 'first', 'Amount': 'sum'})\n",
    "    \n",
    "    # Fill missing data\n",
    "    df.sort_index(ascending=False, kind='mergesort', inplace=True)\n",
    "    bal = df['Balance'].unstack(level=0).transpose().fillna(method='ffill').transpose()\n",
    "    \n",
    "    # Reverse order of columns (dates)\n",
    "    bal = bal.loc[:,::-1]\n",
    "    \n",
    "    # Save to file\n",
    "    bal.to_csv(output_file, sep='\\t')\n",
    "\n",
    "    return bal\n",
    "\n",
    "CalculateBalances(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:\\\\Users\\\\svecon\\\\Google Drive\\\\Finance\\\\Statements\\\\'\n",
    "df = LoadAllTransactions(folder, '*')\n",
    "# df.to_csv('all_transactions.csv', sep='\\t')\n",
    "df = df.round(decimals=2)\n",
    "df = df.replace('', np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = gc.open('Expenses')\n",
    "d2g.upload(df.fillna(''), sheet.id, '2019', credentials=credentials, row_names=False, value_input_opt='USER_ENTERED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsheet = g2d.download(gfile=sheet.id, col_names=True, row_names=False, credentials=credentials)\n",
    "orig = dfsheet.dtypes.to_dict()\n",
    "orig.update(df.dtypes.to_dict())\n",
    "dfsheet = dfsheet.replace('', np.nan).apply(lambda x: x.astype(orig[x.name]))\n",
    "dfsheet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(df.columns)\n",
    "inner = pd.merge(df, dfsheet, on=keys, how='inner')\n",
    "inner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([inner,df]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsheet['Description']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
